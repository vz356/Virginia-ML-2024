{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Homework 2__\n",
    "-\n",
    "\n",
    "__Due Date:__ 2022-10-16 at 8:30 AM PT\n",
    "\n",
    "\n",
    "__Name:__ Virginia\n",
    "\n",
    "\n",
    "For this assignment, you will practice downloadings, cleaning, and analyzing data from the [National Risk Index (NRI)](https://hazards.fema.gov/nri/) and the [CDC Social Vulnerability Index (SVI)](https://www.atsdr.cdc.gov/placeandhealth/svi/index.html).\n",
    "\n",
    "# Preparation\n",
    "\n",
    "1. Create a 'data' folder in the root directory of your repository.\n",
    "1. Inside the 'data' folder, create a 'raw' folder.\n",
    "1. Add and commit a '.gitignore' file to the root directory of this repository that excludes all contents of the 'data' folder.\n",
    "1. Download the county-level NRI and SVI data for the entire United States. Place the data in the 'data/raw' folder.\n",
    "1. In the repository README, provide a brief (1-2 sentence) description of each file in the 'data' folder and a link to the original source of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - NRI Data Cleaning\n",
    "\n",
    "__1. Import the NRI data. Ensure that the [FIPS code](https://en.wikipedia.org/wiki/Federal_Information_Processing_Standard_state_code) variable ('STCOFIPS') is correctly identified as a string / character variable. Otherwise, the leading zeros will be removed.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\vzhang\\\\code\\\\Virginia-ML-2024\\\\Homework'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OID_  NRI_ID    STATE STATEABBRV  STATEFIPS   COUNTY COUNTYTYPE  \\\n",
      "0     1  C01001  Alabama         AL          1  Autauga     County   \n",
      "1     2  C01003  Alabama         AL          1  Baldwin     County   \n",
      "2     3  C01005  Alabama         AL          1  Barbour     County   \n",
      "3     4  C01007  Alabama         AL          1     Bibb     County   \n",
      "4     5  C01009  Alabama         AL          1   Blount     County   \n",
      "\n",
      "   COUNTYFIPS STCOFIPS  POPULATION  ...  WNTW_EALS            WNTW_EALR  \\\n",
      "0           1    01001       58764  ...  15.784587             Very Low   \n",
      "1           3    01003      231365  ...  56.205509  Relatively Moderate   \n",
      "2           5    01005       25160  ...  18.632002       Relatively Low   \n",
      "3           7    01007       22239  ...  13.308573             Very Low   \n",
      "4           9    01009       58992  ...  23.645930       Relatively Low   \n",
      "\n",
      "      WNTW_ALRB     WNTW_ALRP     WNTW_ALRA WNTW_ALR_NPCTL    WNTW_RISKV  \\\n",
      "0  2.687716e-07  7.410082e-09  8.725777e-06      10.461158   8494.906508   \n",
      "1  1.268231e-09  2.287120e-08  1.548360e-07      13.339523  65619.701638   \n",
      "2  5.788050e-07  2.347236e-08  7.606598e-07      16.125039  15501.730335   \n",
      "3  9.014679e-07  1.270300e-08  1.202015e-05      16.991643   7496.186940   \n",
      "4  5.268425e-07  1.482016e-08  2.002965e-07      12.039616  17175.160729   \n",
      "\n",
      "   WNTW_RISKS      WNTW_RISKR     NRI_VER  \n",
      "0   12.217626        Very Low  March 2023  \n",
      "1   52.083996  Relatively Low  March 2023  \n",
      "2   19.535476        Very Low  March 2023  \n",
      "3   11.104041        Very Low  March 2023  \n",
      "4   21.444480        Very Low  March 2023  \n",
      "\n",
      "[5 rows x 465 columns]\n"
     ]
    }
   ],
   "source": [
    "df_nri = pd.read_csv('../data/raw/NRI_Table_Counties.csv', dtype={\"STCOFIPS\": str})\n",
    "print(df_nri.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Subset the NRI data to include only the 5-digit state/county FIPS code and all colums ending with '\\_AFREQ' and '\\_RISKR'. Each of these columns represents a different hazard type.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  STCOFIPS  AVLN_AFREQ  CFLD_AFREQ  CWAV_AFREQ  DRGT_AFREQ  ERQK_AFREQ  \\\n",
      "0    01001         NaN         NaN         0.0   25.969774    0.000431   \n",
      "1    01003         NaN    3.684142         0.0   12.353442    0.000338   \n",
      "2    01005         NaN         NaN         0.0   43.956953    0.000227   \n",
      "3    01007         NaN         NaN         0.0   28.894501    0.000790   \n",
      "4    01009         NaN         NaN         0.0   28.152598    0.000817   \n",
      "\n",
      "   HAIL_AFREQ  HWAV_AFREQ  HRCN_AFREQ  ISTM_AFREQ  ...           ISTM_RISKR  \\\n",
      "0    2.806764    0.371517    0.080450    0.402025  ...             Very Low   \n",
      "1    1.529256    0.939761    0.248233    0.191996  ...       Relatively Low   \n",
      "2    1.908785    0.371517    0.116398    0.393288  ...             Very Low   \n",
      "3    3.447868    0.371517    0.066724    0.413094  ...       Relatively Low   \n",
      "4    5.101344    0.371517    0.039238    0.509665  ...  Relatively Moderate   \n",
      "\n",
      "       LNDS_RISKR           LTNG_RISKR           RFLD_RISKR  \\\n",
      "0  Relatively Low       Relatively Low       Relatively Low   \n",
      "1  Relatively Low            Very High  Relatively Moderate   \n",
      "2  Relatively Low  Relatively Moderate             Very Low   \n",
      "3  Relatively Low       Relatively Low             Very Low   \n",
      "4  Relatively Low  Relatively Moderate             Very Low   \n",
      "\n",
      "            SWND_RISKR           TRND_RISKR         TSUN_RISKR  \\\n",
      "0       Relatively Low  Relatively Moderate     Not Applicable   \n",
      "1       Relatively Low  Relatively Moderate  Insufficient Data   \n",
      "2       Relatively Low  Relatively Moderate     Not Applicable   \n",
      "3       Relatively Low  Relatively Moderate     Not Applicable   \n",
      "4  Relatively Moderate  Relatively Moderate     Not Applicable   \n",
      "\n",
      "       VLCN_RISKR           WFIR_RISKR      WNTW_RISKR  \n",
      "0  Not Applicable             Very Low        Very Low  \n",
      "1  Not Applicable  Relatively Moderate  Relatively Low  \n",
      "2  Not Applicable             Very Low        Very Low  \n",
      "3  Not Applicable             Very Low        Very Low  \n",
      "4  Not Applicable             Very Low        Very Low  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "afreq_cols = [col for col in df_nri.columns if col.endswith('_AFREQ')]\n",
    "riskr_cols = [col for col in df_nri.columns if col.endswith('_RISKR')]\n",
    "\n",
    "keep_cols = ['STCOFIPS'] + afreq_cols + riskr_cols\n",
    "\n",
    "df_nri_sub = df_nri[keep_cols]\n",
    "\n",
    "print(df_nri_sub.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Create a table / dataframe that, for each hazard type, shows the number of missing values in the '\\_AFREQ' and '\\_RISKR' columns.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hazard  Missing_AFREQ  Missing_RISKR\n",
      "0    AVLN           3023              0\n",
      "1    CFLD           2646              0\n",
      "2    CWAV              0              0\n",
      "3    DRGT              7              0\n",
      "4    ERQK              0              0\n",
      "5    HAIL              7              0\n",
      "6    HWAV              0              0\n",
      "7    HRCN            918              0\n",
      "8    ISTM            229              0\n",
      "9    LNDS             40              0\n",
      "10   LTNG            123              0\n",
      "11   RFLD              0              0\n",
      "12   SWND              7              0\n",
      "13   TRND              7              0\n",
      "14   TSUN           3103              0\n",
      "15   VLCN           3125              0\n",
      "16   WFIR             88              0\n",
      "17   WNTW              0              0\n",
      "sum of missing values = 13323\n"
     ]
    }
   ],
   "source": [
    "hazard_types = [col.replace('_AFREQ', '') for col in afreq_cols]\n",
    "\n",
    "# Empty list to store N/A counts\n",
    "na_vals = []\n",
    "\n",
    "# Get counts of N/A for each col\n",
    "for hazard in hazard_types:\n",
    "    afreq_col = f\"{hazard}_AFREQ\"\n",
    "    riskr_col = f\"{hazard}_RISKR\"\n",
    "    \n",
    "    afreq_na = df_nri_sub[afreq_col].isnull().sum()\n",
    "    riskr_na = df_nri_sub[riskr_col].isnull().sum()\n",
    "    \n",
    "    na_vals.append({\n",
    "        'Hazard': hazard,\n",
    "        'Missing_AFREQ': afreq_na,\n",
    "        'Missing_RISKR': riskr_na\n",
    "    })\n",
    "\n",
    "df_na = pd.DataFrame(na_vals)\n",
    "\n",
    "print(df_na)\n",
    "print(f'sum of missing values = {df_nri_sub.isnull().sum().sum()}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. Create a new column in the original data table indicating whether or not 'AVLN_AFREQ' is missing or observed. Show the cross-tabulation of the 'AVLN_AFREQ' missingness and 'AVLN_RISKR' columns (including missing values). What do you observe?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\1955316297.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>na_AVLN_AFREQ</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVLN_RISKR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Not Applicable</th>\n",
       "      <td>0</td>\n",
       "      <td>3023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relatively High</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relatively Low</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relatively Moderate</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very High</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very Low</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "na_AVLN_AFREQ        False  True \n",
       "AVLN_RISKR                       \n",
       "Not Applicable           0   3023\n",
       "Relatively High         15      0\n",
       "Relatively Low          52      0\n",
       "Relatively Moderate     33      0\n",
       "Very High                9      0\n",
       "Very Low                99      0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each column, create new column flagging whether value is N/A\n",
    "for col in df_nri_sub.columns:\n",
    "    df_nri_sub[\"na_\"+col] = df_nri_sub[col].isnull()\n",
    "\n",
    "# Cross-tabs\n",
    "cross_tab = pd.crosstab(df_nri_sub['AVLN_RISKR'], df_nri_sub['na_AVLN_AFREQ'], dropna=False)\n",
    "cross_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations:__\n",
    "\n",
    "AVLN_AFREQ = annualized frequency of avalanches\n",
    "AVLN_RISKR = avalanche Hazard Type Risk Index Rating\n",
    "\n",
    "All counties have non-values for AVLN_RISKR (avalanche risk index), but 3023 counties (the vast majority of counties) have missing values for AVLN_AFREQ (avalanche frequency). This makes sense, since most regions in the US don't have snowy mountains. \n",
    "\n",
    "Among the counties that DO have avalanches, most are low-risk. 99 counties have very low risk avalanches, 52 have relatively low, etc. Only 9 counties' avalanches are very high risk.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5. Assuming that a risk that is \"not applicable\" to a county has an annualized frequency of 0, impute the relevant missing values in the '\\_AFREQ' columns with 0.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  STCOFIPS  AVLN_AFREQ  CFLD_AFREQ  CWAV_AFREQ  DRGT_AFREQ  ERQK_AFREQ  \\\n",
      "0    01001         0.0    0.000000         0.0   25.969774    0.000431   \n",
      "1    01003         0.0    3.684142         0.0   12.353442    0.000338   \n",
      "2    01005         0.0    0.000000         0.0   43.956953    0.000227   \n",
      "3    01007         0.0    0.000000         0.0   28.894501    0.000790   \n",
      "4    01009         0.0    0.000000         0.0   28.152598    0.000817   \n",
      "\n",
      "   HAIL_AFREQ  HWAV_AFREQ  HRCN_AFREQ  ISTM_AFREQ  ...  na_ISTM_RISKR  \\\n",
      "0    2.806764    0.371517    0.080450    0.402025  ...          False   \n",
      "1    1.529256    0.939761    0.248233    0.191996  ...          False   \n",
      "2    1.908785    0.371517    0.116398    0.393288  ...          False   \n",
      "3    3.447868    0.371517    0.066724    0.413094  ...          False   \n",
      "4    5.101344    0.371517    0.039238    0.509665  ...          False   \n",
      "\n",
      "   na_LNDS_RISKR  na_LTNG_RISKR  na_RFLD_RISKR  na_SWND_RISKR  na_TRND_RISKR  \\\n",
      "0          False          False          False          False          False   \n",
      "1          False          False          False          False          False   \n",
      "2          False          False          False          False          False   \n",
      "3          False          False          False          False          False   \n",
      "4          False          False          False          False          False   \n",
      "\n",
      "   na_TSUN_RISKR  na_VLCN_RISKR  na_WFIR_RISKR na_WNTW_RISKR  \n",
      "0          False          False          False         False  \n",
      "1          False          False          False         False  \n",
      "2          False          False          False         False  \n",
      "3          False          False          False         False  \n",
      "4          False          False          False         False  \n",
      "\n",
      "[5 rows x 74 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vzhang\\AppData\\Local\\Temp\\ipykernel_29300\\2257034435.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_nri_sub[afreq_cols] = df_nri_sub[afreq_cols].replace({np.nan:0})\n"
     ]
    }
   ],
   "source": [
    "# Replace M/A values of _AFREQ columns as 0\n",
    "df_nri_sub[afreq_cols] = df_nri_sub[afreq_cols].replace({np.nan:0})\n",
    "print(df_nri_sub.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - SVI Data Cleaning\n",
    "\n",
    "__1. Import the SVI data. Ensure that the FIPS code is correctly identified as a string / character variable. Otherwise, the leading zeros will be removed.__\n",
    "__1. Subset the SVI data to include only the following columns:__\n",
    "`ST, STATE, ST_ABBR, STCNTY, COUNTY, FIPS, LOCATION, AREA_SQMI, E_TOTPOP, EP_POV150, EP_UNEMP, EP_HBURD, EP_NOHSDP, EP_UNINSUR, EP_AGE65, EP_AGE17, EP_DISABL, EP_SNGPNT, EP_LIMENG, EP_MINRTY, EP_MUNIT, EP_MOBILE, EP_CROWD, EP_NOVEH, EP_GROUPQ, EP_NOINT, EP_AFAM, EP_HISP, EP_ASIAN, EP_AIAN, EP_NHPI, EP_TWOMORE, EP_OTHERRACE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ST    STATE ST_ABBR  STCNTY          COUNTY   FIPS  \\\n",
      "0   1  Alabama      AL    1001  Autauga County  01001   \n",
      "1   1  Alabama      AL    1003  Baldwin County  01003   \n",
      "2   1  Alabama      AL    1005  Barbour County  01005   \n",
      "3   1  Alabama      AL    1007     Bibb County  01007   \n",
      "4   1  Alabama      AL    1009   Blount County  01009   \n",
      "\n",
      "                  LOCATION    AREA_SQMI  E_TOTPOP  EP_POV150  ...  EP_NOVEH  \\\n",
      "0  Autauga County, Alabama   594.454786     58761       20.2  ...       4.0   \n",
      "1  Baldwin County, Alabama  1589.861817    233420       18.3  ...       2.3   \n",
      "2  Barbour County, Alabama   885.007619     24877       37.7  ...      11.7   \n",
      "3     Bibb County, Alabama   622.469286     22251       29.0  ...       7.5   \n",
      "4   Blount County, Alabama   644.890376     59077       22.9  ...       4.8   \n",
      "\n",
      "   EP_GROUPQ  EP_NOINT  EP_AFAM  EP_HISP  EP_ASIAN  EP_AIAN  EP_NHPI  \\\n",
      "0        0.9      10.9     19.6      3.2       1.1      0.1      0.0   \n",
      "1        1.5      10.9      8.3      4.8       0.9      0.2      0.0   \n",
      "2       12.0      31.8     46.9      4.8       0.5      0.3      0.0   \n",
      "3        6.4      20.2     20.7      2.9       0.3      0.1      0.0   \n",
      "4        1.0      16.9      1.2      9.7       0.2      0.1      0.2   \n",
      "\n",
      "   EP_TWOMORE  EP_OTHERRACE  \n",
      "0         3.3           0.2  \n",
      "1         3.1           0.4  \n",
      "2         1.8           1.2  \n",
      "3         1.7           0.1  \n",
      "4         2.8           0.1  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "df_svi = pd.read_csv(\"../data/raw/SVI_2022_US_county.csv\", dtype={'FIPS': str})\n",
    "\n",
    "# Step 2: Subset the SVI data to include the required columns\n",
    "keep_cols = [\n",
    "    'ST', 'STATE', 'ST_ABBR', 'STCNTY', 'COUNTY', 'FIPS', 'LOCATION', 'AREA_SQMI',\n",
    "    'E_TOTPOP', 'EP_POV150', 'EP_UNEMP', 'EP_HBURD', 'EP_NOHSDP', 'EP_UNINSUR', 'EP_AGE65',\n",
    "    'EP_AGE17', 'EP_DISABL', 'EP_SNGPNT', 'EP_LIMENG', 'EP_MINRTY', 'EP_MUNIT', 'EP_MOBILE',\n",
    "    'EP_CROWD', 'EP_NOVEH', 'EP_GROUPQ', 'EP_NOINT', 'EP_AFAM', 'EP_HISP', 'EP_ASIAN',\n",
    "    'EP_AIAN', 'EP_NHPI', 'EP_TWOMORE', 'EP_OTHERRACE'\n",
    "]\n",
    "\n",
    "# Subset the dataframe\n",
    "df_svi_sub = df_svi[keep_cols]   \n",
    "print(df_svi_sub.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Create a table / dataframe that shows the number of missing values in each column.\n",
    "(Hint: if you wrote a function for Task 1, you can reuse it here.)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Column  Missing_Values\n",
      "0             ST               0\n",
      "1          STATE               0\n",
      "2        ST_ABBR               0\n",
      "3         STCNTY               0\n",
      "4         COUNTY               0\n",
      "5           FIPS               0\n",
      "6       LOCATION               0\n",
      "7      AREA_SQMI               0\n",
      "8       E_TOTPOP               0\n",
      "9      EP_POV150               0\n",
      "10      EP_UNEMP               0\n",
      "11      EP_HBURD               0\n",
      "12     EP_NOHSDP               0\n",
      "13    EP_UNINSUR               0\n",
      "14      EP_AGE65               0\n",
      "15      EP_AGE17               0\n",
      "16     EP_DISABL               0\n",
      "17     EP_SNGPNT               0\n",
      "18     EP_LIMENG               0\n",
      "19     EP_MINRTY               0\n",
      "20      EP_MUNIT               0\n",
      "21     EP_MOBILE               0\n",
      "22      EP_CROWD               0\n",
      "23      EP_NOVEH               0\n",
      "24     EP_GROUPQ               0\n",
      "25      EP_NOINT               0\n",
      "26       EP_AFAM               0\n",
      "27       EP_HISP               0\n",
      "28      EP_ASIAN               0\n",
      "29       EP_AIAN               0\n",
      "30       EP_NHPI               0\n",
      "31    EP_TWOMORE               0\n",
      "32  EP_OTHERRACE               0\n",
      "Column            STSTATEST_ABBRSTCNTYCOUNTYFIPSLOCATIONAREA_SQM...\n",
      "Missing_Values                                                    0\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Get counts of N/A values for each col\n",
    "na_vals = df_svi_sub.isnull().sum()\n",
    "\n",
    "# Create DF with N/A values\n",
    "df_svi_na = pd.DataFrame({'Column': na_vals.index, 'Missing_Values': na_vals.values})\n",
    "\n",
    "# Print the counts of N/A values for all cols\n",
    "print(df_svi_na)\n",
    "print(df_svi_na.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations:__\n",
    "\n",
    "No missing values in any columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Data Merging\n",
    "__1. Identify any FIPS codes that are present in the NRI data but not in the SVI data and vice versa. Describe any discrepancies and possible causes? What to these discrepancies, if any, mean for interpreting results based on the merged dataset moving forward?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIPS Only in NRI:  {'72017', '72117', '72153', '72055', '72123', '72027', '72097', '72031', '72115', '72089', '72069', '72127', '72001', '72011', '72087', '72063', '72111', '72033', '72003', '72113', '72137', '72041', '72075', '72081', '72015', '72009', '72149', '09007', '09003', '72045', '72037', '72085', '72039', '60050', '72054', '72145', '72119', '72019', '72021', '72129', '72083', '72035', '72103', '72073', '72143', '72139', '09015', '72079', '72023', '72061', '72091', '72067', '69120', '72125', '72059', '72121', '72051', '09013', '72029', '78010', '72135', '72105', '72131', '09005', '72151', '72101', '72077', '72005', '72057', '66010', '72099', '72047', '72053', '72013', '78020', '09011', '72093', '72147', '72007', '09001', '60010', '72065', '69110', '09009', '72107', '78030', '60020', '69100', '72025', '72133', '72071', '72095', '72109', '72049', '72043', '72141'}\n",
      "FIPS Only in SVI:  {'09190', '09170', '09180', '09140', '09130', '09150', '09160', '09120', '09110'}\n"
     ]
    }
   ],
   "source": [
    "# Get FIPS codes from both DFs \n",
    "nri_fips = set(df_nri_sub['STCOFIPS'])\n",
    "svi_fips = set(df_svi_sub['FIPS'])\n",
    "\n",
    "# Get FIPS that are in one DF but not in other\n",
    "fips_only_in_nri = nri_fips - svi_fips\n",
    "fips_only_in_svi = svi_fips - nri_fips\n",
    "\n",
    "# Print the above 2 lists\n",
    "print(\"FIPS Only in NRI: \", fips_only_in_nri)\n",
    "print(\"FIPS Only in SVI: \", fips_only_in_svi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations:__\n",
    "\n",
    "NRI has FIPS for US territories including Puerto Rico (72-), Virgin Islands (78-), Guam (66-), but SVI does not. This means that FEMA reports natural disaster hazard data for US Territories, while the CDC (source of the SVI data) does not report data on social vulnerability those areas.\n",
    "\n",
    "The NRI is only missing a couple FIPS in Connecticut (starting with 09).\n",
    "\n",
    "But both sources are missing some FIPS in Connecticut.\n",
    "\n",
    "The inconsistencies might be due to different data collection methods between FEMA vs. CDC, or different data reporting practices between the 50 US states vs. US Territories.\n",
    "\n",
    "When analyzing the merged dataset, we'll only be able to analyze the relationship between natural disaster hazards and social vulnerability for the FIPS that are in common. I.e., we can't analyze the relationship for US Territories and a few FIPS in Connecticut. We don't have any data on social vulnerability for US Territories, so any findings we have on social vulnerability in the 50 US states cannot be generalized to US Territories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Merge the NRI and SVI data on the FIPS code. Use an outer join to keep all counties in the final dataset.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3240, 107)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge = pd.merge(df_nri_sub, df_svi_sub, left_on='STCOFIPS', right_on='FIPS', how='outer')\n",
    "df_merge.shape  #dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Create a table / dataframe that shows the number of missing values in each column of the merged dataset.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Column  Missing_Values\n",
      "0        STCOFIPS               9\n",
      "1      AVLN_AFREQ               9\n",
      "2      CFLD_AFREQ               9\n",
      "3      CWAV_AFREQ               9\n",
      "4      DRGT_AFREQ               9\n",
      "..            ...             ...\n",
      "102      EP_ASIAN              96\n",
      "103       EP_AIAN              96\n",
      "104       EP_NHPI              96\n",
      "105    EP_TWOMORE              96\n",
      "106  EP_OTHERRACE              96\n",
      "\n",
      "[107 rows x 2 columns]\n",
      "Column            STCOFIPSAVLN_AFREQCFLD_AFREQCWAV_AFREQDRGT_AFR...\n",
      "Missing_Values                                                 3834\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Get counts of N/A values for each col\n",
    "na_vals = df_merge.isnull().sum()\n",
    "\n",
    "# Create DF with N/A values\n",
    "df_merge_na = pd.DataFrame({'Column': na_vals.index, 'Missing_Values': na_vals.values})\n",
    "\n",
    "# Print the counts of N/A values for all cols\n",
    "print(df_merge_na)\n",
    "print(df_merge_na.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
